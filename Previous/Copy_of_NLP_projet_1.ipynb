{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NLP_projet_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopherdiamana/nlp/blob/main/Previous/Copy_of_NLP_projet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS0aLLXsMOY7"
      },
      "source": [
        "# **Introduction to Natural Language Processing 1 Lab03**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNSg4TmUPyhF"
      },
      "source": [
        "```\n",
        "dorian: stemming + bag of words \"BOW counter or list dict\" \n",
        "        prochaine session: stopword + bayesien naif binaire\n",
        "\n",
        "christopher: choix map avec token et nombre d'occ \n",
        "             prochaine session: regard sur la log reg\n",
        "\n",
        "thibaut: familiarisation dataset et cours + debut modele bayesien naif\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0DFtbppHwYV"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxWWRNl_H9B-"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgfDqM5bIN-W"
      },
      "source": [
        "import re\n",
        "\n",
        "re_word = re.compile(r\"^\\w+$\")\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VfWjElyv4Az"
      },
      "source": [
        "Nous avons ici généré les methodes de prétraitement des données par lemmatization et stemming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHKJ50y4J399"
      },
      "source": [
        "def tokenize(text):\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdww2rlAIBJG"
      },
      "source": [
        "def stemming_tokenize(text):\n",
        "  stemmed = [stemmer.stem(word) for word in word_tokenize(text.lower()) if re_word.match(word)]\n",
        "  return stemmed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwKv9aOYRCe1"
      },
      "source": [
        "def lemmatization_tokenize(text):\n",
        "  lemmas = [token.lemma_ for token in lemmatizer(text.lower()) if re_word.match(token.text)]\n",
        "  return lemmas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULe4kFACOiUi"
      },
      "source": [
        "imdb_hugging_train = load_dataset('imdb', ignore_verifications=True, split='train')\n",
        "imdb_hugging_test = load_dataset('imdb', ignore_verifications=True, split='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-F-4K5LB88d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b68e15e-f1d1-48b6-fdfe-34bd40dbdbd4"
      },
      "source": [
        "imdb_hugging_train['text'][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!',\n",
              " 'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.',\n",
              " 'Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I\\'m a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).',\n",
              " 'This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).',\n",
              " 'This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTvJxzJMCBG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a06b0cd-f6d6-4031-d9f0-63f4cb212f1f"
      },
      "source": [
        "imdb_hugging_train['label'][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZHC5DsT9GGf"
      },
      "source": [
        "def text_to_token(data):\n",
        "  toks = []\n",
        "  for line in data['text']:\n",
        "    toks.append(tokenize(line))\n",
        "  return toks\n",
        "\n",
        "def text_to_stem_token(data):\n",
        "  toks = []\n",
        "  for line in data['text']:\n",
        "    toks.append(stemming_tokenize(line))\n",
        "  return toks\n",
        "\n",
        "def text_to_lem_token(data):\n",
        "  toks = []\n",
        "  for line in data['text']:\n",
        "    toks.append(lemmatization_tokenize(line))\n",
        "  return toks\n",
        "\n",
        "def get_labels(data):\n",
        "  return data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6okUkhMJ_x4c"
      },
      "source": [
        "y_train = get_labels(imdb_hugging_train[:5])\n",
        "tok_by_reviews = text_to_token(imdb_hugging_train)\n",
        "tok_by_lem_reviews = text_to_lem_token(imdb_hugging_train)\n",
        "tok_by_stem_reviews = text_to_stem_token(imdb_hugging_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKjkD1F6zDzg"
      },
      "source": [
        "ici on a généré trois liste de liste de tokens formé a partir de tokenization avec ou non du prétraitement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4bRvrnsUgz5"
      },
      "source": [
        "y_train[0], tok_by_reviews[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyT0VnxeWSTD"
      },
      "source": [
        "sum([tok_by_reviews[0].count(x) for x in ['i', 'a']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xShzYeJGG2gi"
      },
      "source": [
        "tok_counts = Counter(tok_by_reviews[0])\n",
        "tok_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkfAZlh_Wexn"
      },
      "source": [
        "def full_vocab_histo(docs_post_treatment): ##cette fonction permet de générer un histogramme qui nous permettra de compter l'occurence des mots\n",
        "  vocab = Counter()\n",
        "  for doc in docs_post_treatment:\n",
        "    vocab = vocab + (Counter(doc))\n",
        "  return vocab\n",
        "\n",
        "def full_vocab_no_histo(docs_post_treatment): ##afin d'avoir une fonction plus rapide, on gere avec un set pour la présence ou pas des mots\n",
        "  vocab = set()\n",
        "  for doc in docs_post_treatment:\n",
        "    vocab = vocab.union(set(doc))\n",
        "  return vocab\n",
        "\n",
        "#full_vocab_histo(tok_by_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jztngsy6F4BM"
      },
      "source": [
        "def train_bayes(doc, labels, classes): \n",
        "  '''\n",
        "    doc: array of reviews split into tokens\n",
        "    labels: array of labels where labels[i] is the ith review's label\n",
        "    classes: array containing all unique label names \n",
        "  '''\n",
        "\n",
        "  log_likelihood = {}\n",
        "  logprior = {}\n",
        "\n",
        "  ndoc = len(doc)\n",
        "  vocab = full_vocab_no_histo(doc)\n",
        "  len_vocab = len(vocab)\n",
        "\n",
        "  for class_name in classes:\n",
        "    nclass = labels.count(class_name)\n",
        "    logprior[class_name] = np.log(nclass / ndoc)\n",
        "    bigdoc = [doc[i] for i in range(ndoc) if labels[i] == class_name]\n",
        "\n",
        "    #Necessary operations to reduce computation\n",
        "    class_vocab = full_vocab_histo(bigdoc)\n",
        "    full_count_class_vocab = sum(class_vocab.values())\n",
        "\n",
        "    for word in vocab:\n",
        "      count_word = class_vocab[word]\n",
        "      log_likelihood[(word, class_name)] = np.log((count_word + 1) / (full_count_class_vocab + len_vocab - 1))\n",
        "\n",
        "  return logprior, log_likelihood, vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bafecqMMhenW"
      },
      "source": [
        "def train_bayes_naifs_binaires(doc, labels, classes):\n",
        "  '''\n",
        "    doc: array of reviews split into tokens\n",
        "    labels: array of labels where labels[i] is the ith review's label\n",
        "    classes: array containing all unique label names (here [neg (or 0), pos (or 1)])\n",
        "  '''\n",
        "\n",
        "  log_likelihood = {}\n",
        "  logprior = {}\n",
        "\n",
        "  ndoc = len(doc)\n",
        "  vocab = full_vocab_no_histo(doc)\n",
        "  len_vocab = len(vocab)\n",
        "  for class_name in classes:\n",
        "    nclass = labels.count(class_name)\n",
        "    logprior[class_name] = np.log(nclass / ndoc)\n",
        "    bigdoc = [doc[i] for i in range(ndoc) if labels[i] == class_name]\n",
        "\n",
        "    #Necessary operations to reduce computation\n",
        "    class_vocab = full_vocab_no_histo(bigdoc)\n",
        "\n",
        "    for word in vocab:\n",
        "      log_likelihood[(word, class_name)] = ({word} & class_vocab == {word}) #equation to return 1 if word exist in class_vocab else return 0\n",
        "\n",
        "  return logprior, log_likelihood, vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRT6Wtrmhw9O"
      },
      "source": [
        "def test_naive_bayes(testdoc, logprior, log_likelihood, classes, V, pretreatment=tokenize):\n",
        "    '''\n",
        "      testdoc: string\n",
        "      logprior: array of value where logprior[i] return a value of the ratio of the training set for the classes[i]\n",
        "      log_likelood: array of value where log_likelood[i] return the probabilitate of the event i\n",
        "      classes:  array containing all unique label names (here [neg (or 0), pos (or 1)])\n",
        "      V : vocabulary containing the word of the training\n",
        "      pretreatment: choose the correct fonction to adapt the input to the model chosen\n",
        "    '''\n",
        "    token_list = pretreatment(testdoc)\n",
        "    sum = [0 for k in range(len(classes))]\n",
        "    for i in range(len(classes)):\n",
        "      sum[i] = logprior[classes[i]]\n",
        "      for word in token_list:\n",
        "        if word in V:\n",
        "          sum[i] += log_likelihood[(word, classes[i])]\n",
        "    max_indice = sum.index(max(sum))\n",
        "    return classes[max_indice]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxZKZYm6fUF3"
      },
      "source": [
        "### training the bayes modeles\n",
        "Dans cette section, nous allons générer nos divers modeles avec nos données sous different format de prétraitement.\n",
        "  * without pretreatment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUzRiRJMff4L"
      },
      "source": [
        "logprior_class, log_likelihood_class, vocab_class = train_bayes(tok_by_reviews, imdb_hugging_train['label'], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaRUDgFFffpk"
      },
      "source": [
        "logprior_binary_class, log_likelihood_binary_class, vocab_binary_class = train_bayes_naifs_binaires(tok_by_reviews, imdb_hugging_train['label'], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFGlElgefkXs"
      },
      "source": [
        "* with stemming\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97dOxpzifoa_"
      },
      "source": [
        "logprior_stem, log_likelihood_stem, vocab_stem = train_bayes(tok_by_stem_reviews, imdb_hugging_train['label'], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5jGF9tRfoPz"
      },
      "source": [
        "logprior_binary_stem, log_likelihood_binary_stem, vocab_binary_stem = train_bayes_naifs_binaires(tok_by_stem_reviews, imdb_hugging_train['label'], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_LS2EMWfwGC"
      },
      "source": [
        "* with lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-o5ZPRLf3DI"
      },
      "source": [
        "logprior_lem, log_likelihood_lem, vocab_lem = train_bayes(tok_by_lem_reviews, imdb_hugging_train['label'], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMWw1HklfP4l"
      },
      "source": [
        "logprior_binary_lem, log_likelihood_binary_lem, vocab_binary_lem = train_bayes_naifs_binaires(tok_by_lem_reviews, imdb_hugging_train['label'], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07xxW96NygGX"
      },
      "source": [
        "ici, on a entrainé 6 modeles differents qui sont calculé avec soit un algorithm different soit avec un dataset de training modifié avec ou pas du prétraitement.\n",
        "les modeles seront défini ainsi a partir de 3 variables qui sont le logprior, le loglikehood et le vocab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai6hWuKTf9ZY"
      },
      "source": [
        "### resultat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_sfKiiFu68X"
      },
      "source": [
        "Ici nous allons d'abord mélanger l'ordre de nos test et aussi créer une nouvelle liste aléatoire de review pour tester notre précision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk__ikP5hqBp"
      },
      "source": [
        "import random\n",
        "list_random = [k for k in range(len(imdb_hugging_test['text']))]\n",
        "random.shuffle(list_random)\n",
        "test_list = list_random[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdF1-7hIxB4I"
      },
      "source": [
        "On regarde ici ci pour un exemple aléatoire, on a les 3 modeles qui nous donne une réponse identique a celle correcte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNxgAk3trqEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e31c159-54a8-449c-9c36-9a9b7db2be01"
      },
      "source": [
        "print(test_list[0])\n",
        "print(imdb_hugging_test['text'][test_list[0]])\n",
        "print(imdb_hugging_test['label'][test_list[0]])\n",
        "print(test_naive_bayes(imdb_hugging_test['text'][test_list[0]], logprior_class, log_likelihood_class, [0, 1], vocab_class))\n",
        "print(test_naive_bayes(imdb_hugging_test['text'][test_list[0]], logprior_stem, log_likelihood_stem, [0, 1], vocab_stem, pretreatment=stemming_tokenize))\n",
        "test_naive_bayes(imdb_hugging_test['text'][test_list[0]], logprior_lem, log_likelihood_lem, [0, 1], vocab_lem, pretreatment=lemmatization_tokenize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15739\n",
            "This is probably my least favorite episode. I lived in Cape Girardeau for quite some time. I can tell you there is no ocean or shrimp boats, fresh crab or scallops anywhere near Missouri. Cape Girardeau is the only inland Cape, it's on the Mississippi River. It looked like the license plates were from Mississippi, which may explain why there was so much racial tension. Missouri and Mississippi are 2 completely different states that don't touch one another. There are many roads in and out of town and none of them are Route 6 or Route 666. This whole inaccuracy was very distracting. Also, Cassie did not seem like someone who would want to hang around Dean if she was well educated. I did not buy them as a couple and didn't enjoy the lengthy love scene. Jo was more Dean's style.\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOF6THbxgQym",
        "outputId": "b7431e23-e5e0-4a25-bda0-3a212a7fb4b8"
      },
      "source": [
        "precision = 0\n",
        "precision_stem = 0\n",
        "precision_lem = 0\n",
        "for i in test_list:\n",
        "  if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_class, log_likelihood_class, [0, 1], vocab_class):\n",
        "    precision += 1/len(test_list)\n",
        "  if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_stem, log_likelihood_stem, [0, 1], vocab_stem, pretreatment=stemming_tokenize):\n",
        "    precision_stem += 1/len(test_list)\n",
        "  if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_lem, log_likelihood_lem, [0, 1], vocab_lem, pretreatment=lemmatization_tokenize):\n",
        "    precision_lem += 1/len(test_list)\n",
        "print(precision)\n",
        "print(precision_stem)\n",
        "print(precision_lem)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8095200000002465\n",
            "0.8005600000002375\n",
            "0.8104000000002474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmZ_h0cr0L8L"
      },
      "source": [
        "on observe ici que la précision pour le modele par occurence est de 80% ou plus en moyenne et qu'on a une plus grande précision lorsque on a une prétraitement avec de la lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD-79KG5gTjg",
        "outputId": "2da7df23-f32d-40fb-bdc3-a5405930d04d"
      },
      "source": [
        "precision_bin = 0\n",
        "precision_stem_bin = 0\n",
        "precision_lem_bin = 0\n",
        "for i in test_list:\n",
        "  if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_binary_class, log_likelihood_binary_class, [0, 1], vocab_binary_class):\n",
        "    precision_bin += 1/len(test_list)\n",
        "  if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_binary_stem, log_likelihood_binary_stem, [0, 1], vocab_binary_stem, pretreatment=stemming_tokenize):\n",
        "    precision_stem_bin += 1/len(test_list)\n",
        "  if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_binary_lem, log_likelihood_binary_lem, [0, 1], vocab_binary_lem, pretreatment=lemmatization_tokenize):\n",
        "    precision_lem_bin += 1/len(test_list)\n",
        "print(precision_bin)\n",
        "print(precision_stem_bin)\n",
        "print(precision_lem_bin)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5658800000000028\n",
            "0.5393199999999763\n",
            "0.547079999999984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr4UDTer0bu_"
      },
      "source": [
        "on observe ici que la précision pour le modele par existence est de 53% ou plus en moyenne et qu'on a une plus grande précision lorsque on a une prétraitement avec de la lemmatization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1MBR0AFwXDA"
      },
      "source": [
        "on observe d'apres les résultat précédent que le model ayant le meilleurs tot de succes est celui de bayes avec les données ayant été prétraitré avec une lemmatization. On observe que l'on passe d'ailleurs d'une précision de 85% a 54% lors du passage du classique au binaire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eZanqOcsfrV"
      },
      "source": [
        "## determination de la précision et des valeurs de recall ainsi que le F1 score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkD5BMnNvIia"
      },
      "source": [
        "Ici, nous allons déterminer les valeurs de précision pour les classes ainsi que les valeurs de recall en plus des F1 score avec notre modele ayant eu le meilleur tot de précision, c'est a dire le modele généré avec le bayes naives avec les données prétraité avec une lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muaiNU04sZeW",
        "outputId": "5844975b-154b-4668-8178-e33ee0eebdaf"
      },
      "source": [
        "#on peut ici séparer les cas de vrai positif(VP), vrai negatif(VN), faux positif(FP), faux négatif(FN)\n",
        "nb_pos = 0\n",
        "nb_neg = 0\n",
        "nb_obtain_pos = 0\n",
        "nb_obtain_neg = 0\n",
        "precision_pos = 0\n",
        "precision_neg = 0\n",
        "recall_pos = 0\n",
        "recall_neg = 0\n",
        "for i in test_list:\n",
        "    if imdb_hugging_test['label'][i] == 0:\n",
        "      nb_neg += 1\n",
        "      if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_lem, log_likelihood_lem, [0, 1], vocab_lem, pretreatment=lemmatization_tokenize): #FN\n",
        "        precision_neg += 1\n",
        "        nb_obtain_neg += 1\n",
        "      else: #FP\n",
        "        nb_obtain_pos += 1 \n",
        "    else:\n",
        "      nb_pos += 1\n",
        "      if imdb_hugging_test['label'][i] == test_naive_bayes(imdb_hugging_test['text'][i], logprior_lem, log_likelihood_lem, [0, 1], vocab_lem, pretreatment=lemmatization_tokenize): #VP\n",
        "        precision_pos += 1\n",
        "        nb_obtain_pos += 1\n",
        "      else: #VN\n",
        "        nb_obtain_neg += 1\n",
        "\n",
        "recall_pos = precision_pos / nb_obtain_pos\n",
        "recall_neg = precision_neg / nb_obtain_neg\n",
        "precision_neg /= nb_neg\n",
        "precision_pos /= nb_pos\n",
        "f1_score_pos = (2 * precision_pos * recall_pos) / (precision_pos + recall_pos)\n",
        "f1_score_neg = (2 * precision_neg * recall_neg) / (precision_neg + recall_neg)\n",
        "list_pos = [precision_pos, recall_pos, f1_score_pos]\n",
        "list_neg = [precision_neg, recall_neg, f1_score_neg]\n",
        "\n",
        "print(list_pos)\n",
        "print(list_neg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7468, 0.8556370302474794, 0.7975224263135413]\n",
            "[0.874, 0.7753726046841731, 0.8217374952989847]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGkkxxkbz0-S"
      },
      "source": [
        "on a généré les résultats sous le format:\n",
        "```\n",
        "[precision_pos, recall_pos, f1_score_pos]\n",
        "[precision_neg, recall_neg, f1_score_neg]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJWybwkEf66"
      },
      "source": [
        "## **LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkIhbOU7FE6T"
      },
      "source": [
        "### Features' treatment \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fanm3uZ7I63Z"
      },
      "source": [
        "Download vader_lexicon.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfaT_ogmI9og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4771988e-88f6-41f9-b815-2c310fc309a8"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/cjhutto/vaderSentiment/master/vaderSentiment/vader_lexicon.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-07 15:45:13--  https://raw.githubusercontent.com/cjhutto/vaderSentiment/master/vaderSentiment/vader_lexicon.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 426786 (417K) [text/plain]\n",
            "Saving to: ‘vader_lexicon.txt’\n",
            "\n",
            "vader_lexicon.txt   100%[===================>] 416.78K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-10-07 15:45:13 (11.4 MB/s) - ‘vader_lexicon.txt’ saved [426786/426786]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvSDZtvJPpni"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/vader_lexicon.txt', \n",
        "                 delimiter = \"\\t\", \n",
        "                 names = ('token', 'mean-sentiment-rating', 'standard deviation', 'raw-human-sentiment-ratings'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cQ4UsfdQK6T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1e571b72-1d36-45e2-b2de-5bf8feb46e94"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>mean-sentiment-rating</th>\n",
              "      <th>standard deviation</th>\n",
              "      <th>raw-human-sentiment-ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>$:</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>0.80623</td>\n",
              "      <td>[-1, -1, -1, -1, -3, -1, -3, -1, -2, -1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>%)</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>1.01980</td>\n",
              "      <td>[-1, 0, -1, 0, 0, -2, -1, 2, -1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>%-)</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>1.43178</td>\n",
              "      <td>[-2, 0, -2, -2, -1, 2, -2, -3, -2, -3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&amp;-:</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>1.42829</td>\n",
              "      <td>[-3, -1, 0, 0, -1, -1, -1, 2, -1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&amp;:</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.64031</td>\n",
              "      <td>[0, -1, -1, -1, 1, -1, -1, -1, -1, -1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  token  ...               raw-human-sentiment-ratings\n",
              "0    $:  ...  [-1, -1, -1, -1, -3, -1, -3, -1, -2, -1]\n",
              "1    %)  ...       [-1, 0, -1, 0, 0, -2, -1, 2, -1, 0]\n",
              "2   %-)  ...    [-2, 0, -2, -2, -1, 2, -2, -3, -2, -3]\n",
              "3   &-:  ...      [-3, -1, 0, 0, -1, -1, -1, 2, -1, 2]\n",
              "4    &:  ...    [0, -1, -1, -1, 1, -1, -1, -1, -1, -1]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0wVllSpvEDC"
      },
      "source": [
        "**The threshold values**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJKSWReOvT67"
      },
      "source": [
        "According to the VADER sentiment documentation, the sentiment ratings features were rated on a scale from \"[–4] Extremely Negative\" to \"[4] Extremely Positive\", with allowance for \"[0] Neutral (or Neither, N/A)\". They kept every lexical feature that had a non-zero mean rating, and whose standard deviation was less than 2.5 as determined by the aggregate of those ten independent raters. This left their with just over 7,500 lexical features with validated valence scores that indicated both the sentiment polarity (positive/negative), and the sentiment intensity on a scale from –4 to +4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXnB6Xu10Y_k"
      },
      "source": [
        "Thus, the threshold that I'm going to use is 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b20JRCktfc52"
      },
      "source": [
        "threshold = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVYkcYgbaBnB"
      },
      "source": [
        "df_positive = df[df['mean-sentiment-rating'] > threshold].token\n",
        "positive_lexicon = np.array(df_positive)\n",
        "\n",
        "df_negative = df[df['mean-sentiment-rating'] < threshold].token\n",
        "negative_lexicon = np.array(df_negative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1A5jmhVjd8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ee3c69-ab9c-461d-fd41-ddcb4f9337ee"
      },
      "source": [
        "len(df), len(positive_lexicon), len(negative_lexicon)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7520, 3347, 4173)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw0wGsKCVY1Q"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb-LsNQiPjwA"
      },
      "source": [
        "start_time_lr = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBhHhe0kU3MB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "911a2048-3070-4445-e5ee-d342cf81804f"
      },
      "source": [
        " start_time = time.time()\n",
        "print(len(df_positive[df_positive['token'] == 'accomplishes']))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'token'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-779401b40137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_positive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_positive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'accomplishes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'token'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGG4psGXcQuJ"
      },
      "source": [
        "start_time = time.time()\n",
        "print(int(df_positive.isin(['accomplishes']).sum()))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fL3BAtglgEV"
      },
      "source": [
        "start_time = time.time()\n",
        "print(sum(np.in1d(positive_lexicon, 'accomplishes')))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDu73khbQcMj"
      },
      "source": [
        "imdb_hugging_train['text'][:5][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tb-7b6kS9hz"
      },
      "source": [
        "Application of the following features:\n",
        "\n",
        "* 1 if \"no\" appear in the doc, 0 otherwise\n",
        "* The count of first and second pronouns in the document\n",
        "* 1 if \"!\" is in the document, 0 otherwise\n",
        "* log(word count in the document)\n",
        "* Number of words in the document which are in the positive lexicon\n",
        "* Number of words in the document which are in the negative lexicon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzZBFHouEfk5"
      },
      "source": [
        "import math\n",
        "\n",
        "def text_review_to_vector(string, tokenization_func):\n",
        "\n",
        "  tokens = np.array(tokenization_func(string))\n",
        "\n",
        "  no_appear = 0\n",
        "  pronous_occu = 0\n",
        "  exclamation_mark = 0\n",
        "  log_words = 0\n",
        "  nb_positive_word = 0\n",
        "  nb_negative_word = 0\n",
        "\n",
        "  for token in tokens:\n",
        "    no_appear = 1 if token == 'no' else no_appear\n",
        "    pronous_occu += 1 if token in ['i', 'you'] else 0\n",
        "    exclamation_mark = 1 if token == '!' else no_appear\n",
        "    if token in positive_lexicon:\n",
        "      nb_positive_word += 1\n",
        "    elif token in negative_lexicon:\n",
        "      nb_negative_word += 1\n",
        "\n",
        "  log_words = math.log2(len(tokens))\n",
        "\n",
        "  return [no_appear, pronous_occu, exclamation_mark, log_words, nb_positive_word, nb_negative_word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt9Cz1AeeUFM"
      },
      "source": [
        "def build_review(data, tokenization_func):\n",
        "  features_vect = []\n",
        "  \n",
        "  for line in data['text']:\n",
        "    features_vect.append(text_review_to_vector(line, tokenization_func))\n",
        "\n",
        "  return features_vect, data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3N-uUfRNvDm"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19YZblPf2t83"
      },
      "source": [
        "sub_imdb_hugging_train = imdb_hugging_train[12400:12600]\n",
        "sub_imdb_hugging_test = imdb_hugging_test[12400:12600]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCy9tazRe3Ta"
      },
      "source": [
        "## With or without pretreatment ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrkWEykOfFT_"
      },
      "source": [
        "In this section, we are going to compare our model without pretreatment, with stemming and with lemmatization and see which is the best solution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p-AloMfOeLX"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wo2NunAkMa2"
      },
      "source": [
        "### Logistic regression without pretreatment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiiXE_Ch-JZw"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "X_train, y_train = build_review(imdb_hugging_train, tokenize)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6_DIh0TPSOa"
      },
      "source": [
        "X_test_without_pretreat, y_test_without_pretreat = build_review(sub_imdb_hugging_test, tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MI30DG1rFHm"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeyD57GxkmOw"
      },
      "source": [
        "logisticRegr_without_pretreat = LogisticRegression().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gh7xpYErQ9O"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3qhIu_GlaXi"
      },
      "source": [
        "y_test_pred_without_pretreat = logisticRegr_without_pretreat.predict(X_test_without_pretreat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEWOnvmZlc8H"
      },
      "source": [
        "score = logisticRegr_without_pretreat.score(X_test_without_pretreat, y_test_without_pretreat)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkjFuEI3B7Qh"
      },
      "source": [
        "### Logistic regression with pretreatment (stemming)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQH2iEIgB6qr"
      },
      "source": [
        "#X_train, y_train = build_review(imdb_hugging_train)\n",
        "X_train, y_train = build_review(sub_imdb_hugging_train, stemming_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtemJg1pPNSO"
      },
      "source": [
        "X_test_with_stemming, y_test_with_stemming = build_review(sub_imdb_hugging_test, stemming_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGj9DbRFCGra"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8aUkF0qPBPP"
      },
      "source": [
        "logisticRegr_with_stemming = LogisticRegression().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogTdSZ7HPGkL"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt-b8MsWPKSm"
      },
      "source": [
        "y_test_pred_with_stemming = logisticRegr_with_stemming.predict(X_test_with_stemming)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1je1_aL-PYTW"
      },
      "source": [
        "score = logisticRegr_with_stemming.score(X_test_with_stemming, y_test_with_stemming)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_SJElExQAQT"
      },
      "source": [
        "### Logistic regression with pretreatment (lemmatization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6sOo9RyQcnV"
      },
      "source": [
        "#X_train, y_train = build_review(imdb_hugging_train)\n",
        "X_train, y_train = build_review(sub_imdb_hugging_train, lemmatization_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYPg_O5HTdg6"
      },
      "source": [
        "X_test_with_lemmatization, y_test_with_lemmatization = build_review(sub_imdb_hugging_test, lemmatization_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx1QjCESTIOg"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU-vSKTCS4kf"
      },
      "source": [
        "logisticRegr_with_lemmatization = LogisticRegression().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp2wetXxTKw8"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJoBZYOIS-r8"
      },
      "source": [
        "y_test_pred_with_lemmatization = logisticRegr_with_lemmatization.predict(X_test_with_lemmatization)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joo1Qi8JTBvz"
      },
      "source": [
        "score = logisticRegr_with_lemmatization.score(X_test_with_lemmatization, y_test_with_lemmatization)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS0YpXeZTQmP"
      },
      "source": [
        "### Evaluation measure logistic regression with and without pretreatment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4bxEgdO6qL5"
      },
      "source": [
        "precision_recall_fscore_support(y_test_without_pretreat, y_test_pred_without_pretreat, average=None, labels=[1, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEy4vggwPnxu"
      },
      "source": [
        "precision_recall_fscore_support(y_test_with_stemming, y_test_pred_with_stemming, average=None, labels=[1, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j5599O7TDEO"
      },
      "source": [
        "precision_recall_fscore_support(y_test_with_lemmatization, y_test_pred_with_lemmatization, average=None, labels=[1, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fCIaMxVjgit"
      },
      "source": [
        "The best is ???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g53Lr-Lj8lN"
      },
      "source": [
        "## More features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY3pjLpukCk2"
      },
      "source": [
        "In this section, we are going to add at least 2 more features "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ii4o_gVkKZD"
      },
      "source": [
        "### Feature number 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xui5g3gkOqr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85EVbIFZkPAD"
      },
      "source": [
        "### Feature number 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPEO9e7kSY7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOT_eI64kTT6"
      },
      "source": [
        "### Evaluation measure logistic regression with the added features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewt1dg99kgk2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4zOlNZfkhHz"
      },
      "source": [
        "*justify your choices with observations*\n",
        "\n",
        "As we can see with these features the precision is increase. This is due to ... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOQNEquJk8e5"
      },
      "source": [
        "## With or without regularization ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMNdtPLolDcX"
      },
      "source": [
        "In this section, we are going to compare our model with and without regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eko3bJDglWHx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WymCFBIglgKz"
      },
      "source": [
        "## Wrongly classified samples - Oh no is it possible ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz2XthI-mCAy"
      },
      "source": [
        "In this section, we are going to provide examples of wrongly classified samples, as well as explanations on why these examples were attributed to the wrong class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMRd4K0BPyDL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu2KczWdlhzs"
      },
      "source": [
        "print(\"--- %s seconds ---\" % (time.time() - start_time_lr))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}